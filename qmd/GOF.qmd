---
title: "Goodness of Fit Tests"
format: html
author: Dr. Cohen 
---

## Speed Data

$H_0:$ speed data is normally distributed

$H_1:$ speed data is not normally distributed

```{r}
str(cars)
hist(cars$speed)
mean_speed = mean(cars$speed)
mean_speed
sd_speed = sd(cars$speed)
sd_speed

```

## Shapiro Wilk Test for Normality

```{r}
shapiro.test(cars$speed)
```

`Decision:` P-value is greater than 0.05, then we fail to reject $H_0$. There is evidence to support that speed data is normally distributed with mean = `r mean(cars$speed)` and variance = `r var(cars$speed)`.

## Lilliefors Test for Normality

```{r}
library(nortest)
lillie.test(cars$speed)
```

`Decision:` P-value is greater than 0.05, then we fail to reject $H_0$. There is evidence to support that speed data is normally distributed with mean = `r mean(cars$speed)` and variance = `r var(cars$speed)`.

## Kolmogorov Smirnov Test

```{r}
# Test for N(mean_speed,sd_speed)
ks.test(cars$speed,'pnorm',mean_speed,sd_speed)

# Test for N(0,1)
ks.test(cars$speed,'pnorm')
```

## Chi-squared Test

```{r}
h = hist(cars$speed) # hist of data
Ob = h$counts # observed frequencies in classes


p1 = pnorm(5,mean_speed,sd_speed)# P(X <= 5)
p2 = pnorm(10,mean_speed,sd_speed)-pnorm(5,mean_speed,sd_speed) # P(5<=X <= 10)
p3 = pnorm(15,mean_speed,sd_speed)-pnorm(10,mean_speed,sd_speed) # P(10<=X <= 15)
p4 = pnorm(20,mean_speed,sd_speed)-pnorm(15,mean_speed,sd_speed) # P(15<=X <= 20)
p5 = 1- pnorm(20,mean_speed,sd_speed) # P(X> 20)

Pj = c(p1,p2,p3,p4,p5) # put everything in one array
sum(Pj) # is it = 1?
Ej = Pj*50 # Expected counts
Ej

# Chi-squared test for GOF
chisq.test(x=Ob,p = Pj)
```

The degrees of freedom of the test is $df = C-1-k = 5 -1 - 2 = 2$. K=2 because we did estimate the mean and variance from the sample.

Adjust for degrees of freedom:

```{r}
pvalue <- 1-pchisq(1.3267,df=2)
pvalue
```

## Example with Binomial distribution

Binomial Example : pp.244 18 baseball players with 45 times at-bat. We have the number of hits.

| \# hits    | \<=7 | 8   | 9   | 10  | 11  | 12  | 13  | 14  | 15  | 16  | 17  |
|------------|------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
| \# players | 1    | 1   | 1   | 5   | 2   | 1   | 1   | 2   | 1   | 1   | 1   |

Consider X is the \# hits, X $\sim$ binom(n= 45, p=? )

```{r}
Ob=c(1,1,1,5,2,1,1,2,1,1,1,1)

# Estimate p- probability that a player will get a hit at-bat.
# p = #hits/total #of at-bats
p= sum((7:18)*Ob) / (18*45)

p1 <- pbinom(7,45,prob = p)
p2 <- dbinom(8:17,45,prob = p)
p12 <- pbinom(17,45,p,lower.tail = F)

Pj <- c(p1,p2,p12)

Ej=Pj*18

# Chi-squared test 
chisq.test(x=Ob,p=Pj)
```

Since the expected values are less than 5. We combine classes.

```{r}
Ob=c(8,6,4)
p1 <- pbinom(10,45,prob = p) # P(X<=10)
p2 <- sum(dbinom(11:14,45,prob = p)) # P(11<=X<=14)
p3 <- pbinom(14,45,p,lower.tail = F)# P(X>=15)
Pj <- c(p1,p2,p3)
sum(Pj)

Ej=Pj*18
Ej
# Chi-squared test 
chisq.test(x=Ob,p=Pj)
```

The degrees of freedom of the test is $df = C-1-k = 3 -1 - 1 = 1$. K=1 because we estimated the probability of hitting at bat from the sample.

Adjust for degrees of freedom:

```{r}
pvalue <- 1-pchisq(1.8222,df=1)
pvalue
```
